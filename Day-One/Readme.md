![image](https://github.com/user-attachments/assets/c04e5713-234b-42f0-9f73-10bd45f0b190)

## Day 1 Assignments:

### Complete the Intro Unit - “Foundational Large Language Models & Text Generation”, which is:

- ➡️ [Optional] Listen to the summary podcast episode (https://youtu.be/mQDlCZZsOyo) for this unit (created by NotebookLM, https://notebooklm.google.com/).
- ➡️ Read the “Foundational Large Language Models & Text Generation” whitepaper (https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation).

### Complete Unit 1 - “Prompt Engineering”, which is:
![image](https://github.com/user-attachments/assets/2391afdc-8080-47da-879d-6a3a8203c42f)

- ➡️ [Optional] Listen to the summary podcast episode (https://youtu.be/F_hJ2Ey4BNc) for this unit (created by NotebookLM).
- ➡️ Read the “Prompt Engineering” whitepaper (https://www.kaggle.com/whitepaper-prompt-engineering).
- ➡️ Complete this code lab (https://www.kaggle.com/code/markishere/day-1-prompting) on Kaggle where you’ll learn prompting fundamentals. Make sure you phone verify (https://www.kaggle.com/settings) your account before starting, it's necessary for the code labs.

## 💡 What You’ll Learn
Today you’ll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You’ll also get trained in the art of prompt engineering for optimal LLM interaction.

The code lab will walk you through getting started with the Gemini API and cover several prompt techniques and how different parameters impact the prompts.

## playlist of all livestreams:
 https://www.youtube.com/playlist?list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es
