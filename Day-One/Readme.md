![image](https://github.com/user-attachments/assets/c04e5713-234b-42f0-9f73-10bd45f0b190)

### Introduction
The advent of Large Language Models (LLMs) represents a seismic shift in the world of artificial intelligence. Their ability to process, generate, and understand user intent is fundamentally changing the way we interact with information and technology.
An LLM is an advanced artificial intelligence system that specializes in processing, understanding, and generating human-like text. These systems are typically implemented as a deep neural network and are trained on massive amounts of text data. This allows them to learn the intricate patterns of language, giving them the ability to perform a variety of tasks, like machine translation, creative text generation, question answering, text summarization, and many more reasoning and language oriented tasks. This whitepaper dives into the timeline of the various architectures and approaches building up to the large language models and the architectures being used at the time of publication. It also discusses fine- tuning techniques to customize an LLM to a certain domain or task, methods to make the training more efficient, as well as methods to accelerate inference. These are then followed by various applications and code examples.

## Day 1 Assignments:

### Complete the Intro Unit - ‚ÄúFoundational Large Language Models & Text Generation‚Äù, which is:

- ‚û°Ô∏è [Optional] Listen to the summary podcast episode (https://youtu.be/mQDlCZZsOyo) for this unit (created by NotebookLM, https://notebooklm.google.com/).
- ‚û°Ô∏è Read the ‚ÄúFoundational Large Language Models & Text Generation‚Äù whitepaper (https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation).

### Complete Unit 1 - ‚ÄúPrompt Engineering‚Äù, which is:
![image](https://github.com/user-attachments/assets/2391afdc-8080-47da-879d-6a3a8203c42f)

When thinking about a large language model input and output, a text prompt (sometimes accompanied by other modalities such as image prompts) is the input the model uses to predict a specific output. You don‚Äôt need to be a data scientist or a machine learning engineer ‚Äì everyone can
write a prompt. However, crafting the most effective prompt can be complicated. Many aspects of your prompt affect its efficacy: the model you use, the model‚Äôs training data, the model configurations, your word-choice, style and tone, structure, and context all matter. Therefore,
prompt engineering is an iterative process. Inadequate prompts can lead to ambiguous, inaccurate responses, and can hinder the model‚Äôs ability to provide meaningful output. You don‚Äôt need to be a data scientist or a machine learning engineer ‚Äì everyone can write a prompt.
When you chat with the Gemini chatbot, you basically write prompts, however this whitepaper focuses on writing prompts for the Gemini model within Vertex AI or by using the API, because by prompting the model directly you will have access to the configuration such as temperature etc.
This whitepaper discusses prompt engineering in detail. We will look into the various prompting techniques to help you getting started and share tips and best practices to become a prompting expert. We will also discuss some of the challenges you can face while crafting prompts.

- ‚û°Ô∏è [Optional] Listen to the summary podcast episode (https://youtu.be/F_hJ2Ey4BNc) for this unit (created by NotebookLM).
- ‚û°Ô∏è Read the ‚ÄúPrompt Engineering‚Äù whitepaper (https://www.kaggle.com/whitepaper-prompt-engineering).
- ‚û°Ô∏è Complete this code lab (https://www.kaggle.com/code/markishere/day-1-prompting) on Kaggle where you‚Äôll learn prompting fundamentals. Make sure you phone verify (https://www.kaggle.com/settings) your account before starting, it's necessary for the code labs.

## üí° What You‚Äôll Learn
Today you‚Äôll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You‚Äôll also get trained in the art of prompt engineering for optimal LLM interaction.

The code lab will walk you through getting started with the Gemini API and cover several prompt techniques and how different parameters impact the prompts.

## playlist of all livestreams:
 https://www.youtube.com/playlist?list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es
