# Day 1 Assignments

## Complete the Intro Unit - ‚ÄúFoundational Large Language Models & Text Generation‚Äù, which is:

- ‚û°Ô∏è [Optional] Listen to the summary podcast episode (https://youtu.be/mQDlCZZsOyo) for this unit (created by NotebookLM, https://notebooklm.google.com/).
- ‚û°Ô∏è Read the ‚ÄúFoundational Large Language Models & Text Generation‚Äù whitepaper (https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation).

## Complete Unit 1 - ‚ÄúPrompt Engineering‚Äù, which is:

- ‚û°Ô∏è [Optional] Listen to the summary podcast episode (https://youtu.be/F_hJ2Ey4BNc) for this unit (created by NotebookLM).
- ‚û°Ô∏è Read the ‚ÄúPrompt Engineering‚Äù whitepaper (https://www.kaggle.com/whitepaper-prompt-engineering). 
- ‚û°Ô∏è Complete this code lab (https://www.kaggle.com/code/markishere/day-1-prompting) on Kaggle where you‚Äôll learn prompting fundamentals. Make sure you phone verify (https://www.kaggle.com/settings) your account before starting, it's necessary for the code labs.

# üí° What You‚Äôll Learn
Today you‚Äôll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You‚Äôll also get trained in the art of prompt engineering for optimal LLM interaction.

The code lab will walk you through getting started with the Gemini API and cover several prompt techniques and how different parameters impact the prompts.

# 
# Day 2 Assignments

## Complete Unit 2: ‚ÄúEmbeddings and Vector Stores/Databases‚Äù, which is:
- [Optional] Listen to the summary podcast episode (https://youtube.com/watch?v=1CC39K76Nqs) for this unit (created by NotebookLM, https://notebooklm.google.com/).
- Read the ‚ÄúEmbeddings and Vector Stores/Databases‚Äù whitepaper (https://kaggle.com/whitepaper-embeddings-and-vector-stores).
  
## Complete these code labs on Kaggle:
  ### - Build a RAG question-answering system over custom documents - https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag
  ### - Explore text similarity with embeddings - https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores
  ### - Build a neural classification network with Keras using embeddings - https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras

# üí° What You‚Äôll Learn

Today you will learn about the conceptual underpinning of embeddings and vector databases and how they can be used to bring live or specialist data into your LLM application. You‚Äôll also explore their geometrical powers for classifying and comparing textual data. 

 Reminders and Announcements
-Here is the recording (https://www.youtube.com/watch?v=kpRyiJUUFxY) from this morning‚Äôs livestream. We apologize for the live technical issues today! Fortunately our recording did not have the same errors.
-The 2nd livestream is tomorrow with Paige Bailey (https://x.com/DynamicWebPaige) and special guests: Omid Fatemieh, Jinhyuk Lee, Alan Li, Iftekhar Naim, Anant Nawalgaria, Yan Qiao, and Xiaoqi Ren.
-Unfortunately, to ensure a fix to our livestream issues, we need to push back our broadcast time. We'll send another email with updated livestream info soon.
-Be sure to ask all your questions about the podcast, readings, and code lab in the ‚Å†5dgai-q-and-a channel on Discord. You'll get Kaggle swag if your question is chosen for discussion during the livestream!

# Kaggle GenAI, Tips & Tricks :

https://www.youtube.com/watch?v=v5bhhJ9FD60
